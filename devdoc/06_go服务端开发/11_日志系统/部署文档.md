# 日志系统 - 部署文档

## 1. 概述
本文档描述了日志系统的部署方案，包括环境准备、安装配置、启动停止、升级迁移等内容。日志系统作为游戏服务端的重要组成部分，需要确保其稳定运行和可靠存储。

## 2. 环境准备

### 2.1 硬件要求

| 项目 | 最低配置 | 推荐配置 |
|------|----------|----------|
| CPU | 2核 | 4核+ |
| 内存 | 4GB | 8GB+ |
| 磁盘 | 100GB | 500GB+ |
| 网络 | 千兆以太网 | 万兆以太网 |

### 2.2 软件要求

| 项目 | 版本 | 用途 |
|------|------|------|
| 操作系统 | Ubuntu 20.04 LTS 或 CentOS 7+ | 运行环境 |
| Go | 1.18+ | 编译和运行 |
| MySQL | 8.0+ | 存储结构化日志 (可选) |
| Redis | 6.0+ | 缓存和队列 (可选) |
| Elasticsearch | 7.10+ | 日志存储和搜索 (可选) |
| Logstash | 7.10+ | 日志收集和处理 (可选) |
| Kibana | 7.10+ | 日志可视化和分析 (可选) |
| Prometheus | 2.20+ | 监控 (可选) |
| Grafana | 7.0+ | 监控可视化 (可选) |

### 2.3 网络要求

| 项目 | 要求 | 用途 |
|------|------|------|
| 网络带宽 | 100Mbps+ | 日志传输和远程访问 |
| 防火墙 | 开放必要端口 | 允许日志收集和监控 |
| 网络延迟 | <10ms | 确保日志实时性 |

### 2.4 存储要求

| 项目 | 要求 | 用途 |
|------|------|------|
| 本地存储 | SSD | 存储热日志和应用程序 |
| 远程存储 | NAS/SAN | 存储冷日志和备份 |
| 备份存储 | 独立存储 | 存储日志备份 |

## 3. 部署方案

### 3.1 单机部署

**适用场景**：开发环境、测试环境、小型游戏服务端

**部署架构**：
- 单台服务器运行所有组件
- 本地文件存储日志
- 可选集成ELK Stack

**部署步骤**：
1. **安装依赖**：
   ```bash
   # Ubuntu
   apt update && apt install -y git curl
   
   # CentOS
   yum update && yum install -y git curl
   ```

2. **安装Go**：
   ```bash
   # 下载Go
   curl -O https://golang.org/dl/go1.18.3.linux-amd64.tar.gz
   
   # 解压
   tar -xzf go1.18.3.linux-amd64.tar.gz
   mv go /usr/local
   
   # 配置环境变量
   echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc
   source ~/.bashrc
   ```

3. **安装日志系统**：
   ```bash
   # 克隆代码
   git clone https://github.com/pixb/DnfGameServer.git
   cd DnfGameServer/dnf-go-server
   
   # 编译
   go build -o logs-server ./cmd/logs-server
   
   # 复制配置文件
   cp config/logs.example.json config/logs.json
   ```

4. **配置日志系统**：
   - 编辑 `config/logs.json` 文件，配置日志级别、处理器、格式化器等

5. **启动日志系统**：
   ```bash
   ./logs-server -config=config/logs.json
   ```

### 3.2 集群部署

**适用场景**：生产环境、大型游戏服务端

**部署架构**：
- 多台应用服务器运行日志生成组件
- 独立的日志收集服务器运行Logstash
- 独立的存储服务器运行Elasticsearch
- 独立的监控服务器运行Prometheus和Grafana

**部署步骤**：
1. **应用服务器部署**：
   - 按照单机部署步骤安装日志生成组件
   - 配置日志收集到Logstash

2. **日志收集服务器部署**：
   - 安装Logstash
   - 配置Logstash管道，接收来自应用服务器的日志
   - 配置Logstash输出到Elasticsearch

3. **存储服务器部署**：
   - 安装Elasticsearch集群
   - 配置Elasticsearch索引模板和生命周期管理
   - 配置Elasticsearch备份

4. **可视化服务器部署**：
   - 安装Kibana
   - 配置Kibana连接Elasticsearch
   - 创建Kibana仪表板

5. **监控服务器部署**：
   - 安装Prometheus
   - 配置Prometheus监控日志系统
   - 安装Grafana
   - 配置Grafana连接Prometheus
   - 创建监控仪表板

### 3.3 容器化部署

**适用场景**：开发环境、测试环境、生产环境

**部署架构**：
- 使用Docker容器运行各个组件
- 使用Docker Compose或Kubernetes管理容器

**部署步骤**：
1. **安装Docker和Docker Compose**：
   ```bash
   # 安装Docker
   curl -fsSL https://get.docker.com -o get-docker.sh
   sh get-docker.sh
   
   # 安装Docker Compose
   curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
   chmod +x /usr/local/bin/docker-compose
   ```

2. **创建Docker Compose文件**：
   ```yaml
   version: '3'
   services:
     logs-server:
       build: .
       ports:
         - "8080:8080"
       volumes:
         - ./config:/app/config
         - ./logs:/app/logs
       environment:
         - LOG_LEVEL=info
       depends_on:
         - elasticsearch
         - redis
     
     elasticsearch:
       image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
       environment:
         - discovery.type=single-node
         - ES_JAVA_OPTS=-Xms1g -Xmx1g
       ports:
         - "9200:9200"
       volumes:
         - es_data:/usr/share/elasticsearch/data
     
     kibana:
       image: docker.elastic.co/kibana/kibana:7.17.0
       ports:
         - "5601:5601"
       depends_on:
         - elasticsearch
     
     redis:
       image: redis:6.0
       ports:
         - "6379:6379"
     
     prometheus:
       image: prom/prometheus:v2.30.0
       ports:
         - "9090:9090"
       volumes:
         - ./prometheus.yml:/etc/prometheus/prometheus.yml
     
     grafana:
       image: grafana/grafana:8.2.0
       ports:
         - "3000:3000"
       depends_on:
         - prometheus

   volumes:
     es_data:
   ```

3. **构建和启动容器**：
   ```bash
   docker-compose build
   docker-compose up -d
   ```

4. **验证部署**：
   - 访问 Kibana: http://localhost:5601
   - 访问 Grafana: http://localhost:3000

## 4. 配置管理

### 4.1 配置文件

**配置文件格式**：支持JSON和YAML格式

**配置文件位置**：
- 默认：`config/logs.json` 或 `config/logs.yaml`
- 可通过命令行参数指定：`-config=path/to/config.json`

**配置示例** (JSON)：
```json
{
  "level": "info",
  "handlers": [
    {
      "type": "console"
    },
    {
      "type": "file",
      "config": {
        "path": "./logs/app.log"
      }
    },
    {
      "type": "async",
      "config": {
        "target": "file",
        "path": "./logs/async.log",
        "buffer_size": "1024"
      }
    }
  ],
  "formatter": "text",
  "fields": {
    "app": "dnf-game-server",
    "env": "production"
  }
}
```

**配置示例** (YAML)：
```yaml
level: info
handlers:
  - type: console
  - type: file
    config:
      path: ./logs/app.log
  - type: async
    config:
      target: file
      path: ./logs/async.log
      buffer_size: "1024"
formatter: text
fields:
  app: dnf-game-server
  env: production
```

### 4.2 环境变量

**支持的环境变量**：

| 环境变量 | 描述 | 默认值 |
|---------|------|--------|
| LOG_LEVEL | 日志级别 | info |
| LOG_CONFIG | 配置文件路径 | config/logs.json |
| LOG_DIR | 日志目录 | ./logs |
| LOG_FILE | 日志文件名 | app.log |
| LOG_MAX_SIZE | 日志文件最大大小 | 100MB |
| LOG_MAX_BACKUPS | 日志文件最大备份数 | 10 |
| LOG_MAX_AGE | 日志文件最大保留天数 | 30 |
| ES_URL | Elasticsearch URL | http://localhost:9200 |
| REDIS_URL | Redis URL | redis://localhost:6379 |

**使用环境变量**：
```bash
# 启动时设置环境变量
LOG_LEVEL=debug LOG_DIR=/var/log/dnf ./logs-server
```

### 4.3 命令行参数

**支持的命令行参数**：

| 参数 | 描述 | 默认值 |
|------|------|--------|
| -config | 配置文件路径 | config/logs.json |
| -level | 日志级别 | info |
| -dir | 日志目录 | ./logs |
| -file | 日志文件名 | app.log |
| -host | 服务器主机 | 0.0.0.0 |
| -port | 服务器端口 | 8080 |
| -help | 显示帮助信息 | - |

**使用命令行参数**：
```bash
./logs-server -config=config/production.json -level=warn -dir=/var/log/dnf
```

## 5. 启动与停止

### 5.1 启动方式

**前台启动**：
```bash
./logs-server -config=config/logs.json
```

**后台启动**：
```bash
nohup ./logs-server -config=config/logs.json > /dev/null 2>&1 &
```

**使用systemd启动**：
1. **创建systemd服务文件**：
   ```bash
   sudo vi /etc/systemd/system/logs-server.service
   ```

2. **编辑服务文件**：
   ```ini
   [Unit]
   Description=Logs Server
   After=network.target
   
   [Service]
   Type=simple
   WorkingDirectory=/opt/DnfGameServer/dnf-go-server
   ExecStart=/opt/DnfGameServer/dnf-go-server/logs-server -config=config/logs.json
   Restart=always
   RestartSec=5
   Environment=LOG_LEVEL=info
   Environment=LOG_DIR=/var/log/dnf
   
   [Install]
   WantedBy=multi-user.target
   ```

3. **启用并启动服务**：
   ```bash
   sudo systemctl daemon-reload
   sudo systemctl enable logs-server
   sudo systemctl start logs-server
   ```

### 5.2 停止方式

**前台停止**：
- 按 `Ctrl+C` 停止

**后台停止**：
```bash
# 查找进程ID
ps aux | grep logs-server
kill <进程ID>
```

**使用systemd停止**：
```bash
sudo systemctl stop logs-server
```

### 5.3 重启方式

**手动重启**：
```bash
# 停止
kill <进程ID>
# 启动
./logs-server -config=config/logs.json
```

**使用systemd重启**：
```bash
sudo systemctl restart logs-server
```

### 5.4 状态检查

**使用systemd检查**：
```bash
sudo systemctl status logs-server
```

**查看日志**：
```bash
tail -f /var/log/dnf/app.log
```

## 6. 升级与迁移

### 6.1 版本升级

**升级步骤**：
1. **备份配置和数据**：
   ```bash
   # 备份配置文件
   cp config/logs.json config/logs.json.bak
   
   # 备份日志数据
   cp -r logs/ logs.bak/
   ```

2. **获取新版本**：
   ```bash
   git pull
   ```

3. **编译新版本**：
   ```bash
   go build -o logs-server ./cmd/logs-server
   ```

4. **替换旧版本**：
   ```bash
   # 停止服务
   sudo systemctl stop logs-server
   
   # 替换二进制文件
   mv logs-server /opt/DnfGameServer/dnf-go-server/logs-server
   
   # 启动服务
   sudo systemctl start logs-server
   ```

5. **验证升级**：
   ```bash
   sudo systemctl status logs-server
   tail -f /var/log/dnf/app.log
   ```

### 6.2 数据迁移

**迁移场景**：
- 从本地文件存储迁移到Elasticsearch
- 从旧版本Elasticsearch迁移到新版本
- 从单节点迁移到集群

**迁移步骤**：
1. **准备目标存储**：
   - 安装并配置目标存储系统
   - 确保目标存储系统可访问

2. **配置迁移工具**：
   - 使用Logstash导入旧日志
   - 或使用Elasticsearch的reindex API

3. **执行迁移**：
   ```bash
   # 使用Logstash导入文件日志
   # 创建logstash配置文件
   vi logstash-file-input.conf
   
   # 启动Logstash
   bin/logstash -f logstash-file-input.conf
   ```

4. **验证迁移**：
   - 检查目标存储中的日志数据
   - 验证日志查询功能

### 6.3 回滚方案

**回滚步骤**：
1. **停止服务**：
   ```bash
   sudo systemctl stop logs-server
   ```

2. **恢复备份**：
   ```bash
   # 恢复配置文件
   cp config/logs.json.bak config/logs.json
   
   # 恢复二进制文件
   cp logs-server.bak logs-server
   ```

3. **启动服务**：
   ```bash
   sudo systemctl start logs-server
   ```

4. **验证回滚**：
   ```bash
   sudo systemctl status logs-server
   tail -f /var/log/dnf/app.log
   ```

## 7. 监控与维护

### 7.1 监控指标

**核心监控指标**：
- **日志写入量**：单位时间内的日志写入量
- **日志查询性能**：日志查询的响应时间
- **处理器错误**：处理器错误的数量
- **异步队列长度**：异步处理器的队列长度
- **存储使用**：日志存储的使用情况
- **系统资源**：CPU、内存、磁盘、网络使用情况

**监控工具**：
- **Prometheus**：收集和存储监控指标
- **Grafana**：可视化监控指标
- **Elasticsearch Monitoring**：监控Elasticsearch性能

### 7.2 维护任务

**日常维护**：
- **日志清理**：定期清理过期日志
- **日志备份**：定期备份重要日志
- **存储检查**：检查存储使用情况
- **性能调优**：根据监控指标调优系统

**定期维护**：
- **每周**：
  - 检查日志系统运行状态
  - 清理过期日志
  - 备份重要日志

- **每月**：
  - 分析日志系统性能
  - 调优系统配置
  - 检查存储使用情况

- **每季度**：
  - 全面系统检查
  - 升级系统版本
  - 归档历史日志

### 7.3 故障处理

**常见故障**：

| 故障类型 | 症状 | 可能原因 | 处理方法 |
|---------|------|----------|----------|
| 日志写入失败 | 应用无错误，但日志未写入 | 文件权限问题 | 检查文件权限 |
| 日志查询缓慢 | 查询响应时间长 | 索引未优化 | 优化Elasticsearch索引 |
| 存储已满 | 磁盘空间不足 | 日志清理不及时 | 清理过期日志，增加存储 |
| 处理器错误 | 日志中出现处理器错误 | 处理器配置错误 | 检查处理器配置 |
| 异步队列阻塞 | 日志处理延迟高 | 队列满 | 增加队列大小，提高处理速度 |

**故障处理流程**：
1. **故障发现**：通过监控系统或用户反馈发现故障
2. **故障定位**：分析日志和监控指标，定位故障原因
3. **故障处理**：根据故障类型采取相应的处理措施
4. **故障验证**：验证故障是否已解决
5. **故障记录**：记录故障原因和处理措施，便于后续分析

## 8. 安全管理

### 8.1 访问控制

**文件权限**：
- 日志文件权限：`644` (owner: rw-, group: r--, others: r--)
- 配置文件权限：`640` (owner: rw-, group: r--, others: ---)
- 二进制文件权限：`755` (owner: rwx, group: r-x, others: r-x)

**目录权限**：
- 日志目录权限：`755` (owner: rwx, group: r-x, others: r-x)
- 配置目录权限：`750` (owner: rwx, group: r-x, others: ---)

**用户权限**：
- 运行日志系统的用户应具有最小必要权限
- 避免使用root用户运行日志系统

### 8.2 数据安全

**敏感信息保护**：
- 配置敏感信息过滤器，过滤密码、令牌等敏感信息
- 对敏感日志使用加密存储

**数据传输安全**：
- 使用HTTPS传输日志数据
- 使用TLS加密Elasticsearch和Logstash通信

**数据备份**：
- 定期备份日志数据
- 备份数据存储在安全的位置
- 备份数据加密存储

### 8.3 网络安全

**防火墙配置**：
- 只开放必要的端口
- 限制访问源IP

**入侵检测**：
- 监控异常的日志访问
- 部署入侵检测系统

**DDoS防护**：
- 配置DDoS防护措施
- 限制单个IP的请求频率

## 9. 故障排查

### 9.1 日志系统故障

**故障现象**：日志系统无法启动或运行异常

**排查步骤**：
1. **检查系统日志**：
   ```bash
   journalctl -u logs-server
   ```

2. **检查应用日志**：
   ```bash
   tail -f /var/log/dnf/app.log
   ```

3. **检查配置文件**：
   ```bash
   cat config/logs.json
   ```

4. **检查依赖服务**：
   ```bash
   # 检查Elasticsearch
   curl -X GET http://localhost:9200
   
   # 检查Redis
   redis-cli ping
   ```

5. **检查端口占用**：
   ```bash
   netstat -tuln | grep 8080
   ```

### 9.2 日志收集故障

**故障现象**：日志无法收集到中央存储

**排查步骤**：
1. **检查应用服务器日志**：
   ```bash
   tail -f /var/log/dnf/app.log
   ```

2. **检查Logstash状态**：
   ```bash
   sudo systemctl status logstash
   tail -f /var/log/logstash/logstash-plain.log
   ```

3. **检查网络连接**：
   ```bash
   # 检查应用服务器到Logstash的连接
   telnet logstash-server 5044
   
   # 检查Logstash到Elasticsearch的连接
   telnet elasticsearch-server 9200
   ```

4. **检查Logstash配置**：
   ```bash
   cat /etc/logstash/conf.d/logstash.conf
   ```

### 9.3 日志查询故障

**故障现象**：日志查询无结果或响应缓慢

**排查步骤**：
1. **检查Elasticsearch状态**：
   ```bash
   sudo systemctl status elasticsearch
   curl -X GET http://localhost:9200/_cat/health
   ```

2. **检查Elasticsearch索引**：
   ```bash
   curl -X GET http://localhost:9200/_cat/indices
   ```

3. **检查查询语句**：
   - 验证查询语句是否正确
   - 检查查询条件是否过于复杂

4. **检查Elasticsearch性能**：
   ```bash
   curl -X GET http://localhost:9200/_nodes/stats
   ```

## 10. 总结

本文档详细描述了日志系统的部署方案，包括环境准备、部署架构、配置管理、启动停止、升级迁移、监控维护、安全管理和故障排查等内容。通过合理的部署和配置，可以确保日志系统的稳定运行和可靠存储，为游戏服务端的运行状态监控、问题排查、用户行为分析、业务数据分析和安全审计提供重要支持。

在实际部署过程中，应根据具体的业务需求和系统规模，选择合适的部署方案和配置策略，确保日志系统能够满足实际需求。同时，应定期对日志系统进行监控和维护，及时发现和处理问题，确保系统的稳定运行。